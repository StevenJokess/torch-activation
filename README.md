# PyTorch Activations

## ELU activation function

![ELU activation function](fig/ELU.png)

## Hardshrink activation function

![Hardshrink activation function](fig/Hardshrink.png)

## Hardsigmoid activation function

![Hardsigmoid activation function](fig/Hardsigmoid.png)

## Hardtanh activation function

![Hardtanh activation function](fig/Hardtanh.png)

## Hardswish activation function

![Hardswish activation function](fig/Hardswish.png)

## LeakyReLU activation function

![LeakyReLU activation function](fig/LeakyReLU.png)

## LogSigmoid activation function

![LogSigmoid activation function](fig/LogSigmoid.png)

## ReLU activation function

![ReLU activation function](fig/ReLU.png)

## ReLU6 activation function

![ReLU6 activation function](fig/ReLU6.png)

## SELU activation function

![SELU activation function](fig/SELU.png)

## CELU activation function

![CELU activation function](fig/CELU.png)

## GELU activation function

![GELU activation function](fig/GELU.png)

## Sigmoid activation function

![Sigmoid activation function](fig/Sigmoid.png)

## Softplus activation function

![Softplus activation function](fig/Softplus.png)

## Softshrink activation function

![Softshrink activation function](fig/Softshrink.png)

## Softsign activation function

![Softsign activation function](fig/Softsign.png)

## Tanh activation function

![Tanh activation function](fig/Tanh.png)

## Tanhshrink activation function

![Tanhshrink activation function](fig/Tanhshrink.png)

## Threshold activation function

![Threshold activation function](fig/Threshold.png)

